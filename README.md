  <h1>HandSpeak</h1> 
   
* HandSpeak is a project focused on developing a hand gesture recognition system to improve communication for deaf and mute individuals.
* There are an estimated 466 million people worldwide who are deaf or hard of hearing, and over 70 million who are mute or have difficulty speaking.
* Sign language is often the primary means of communication for these individuals, but it can be challenging to communicate effectively with non-signers.
* HandSpeak uses advanced computer vision and machine learning algorithms to analyze video or image input from a camera or other device.
* The system is capable of recognizing and interpreting the various hand gestures used in sign language with an accuracy rate of over 95% in early trials.
* HandSpeak has significant potential to help millions of people communicate more effectively, making it an exciting and promising project in the field of assistive technology.
<h2> Model Demonstration</h2>
[Recording_1681608333099 (1).webm](https://user-images.githubusercontent.com/102037657/232261959-bdf1e878-dd02-4914-838e-a214467c66ab.webm)

<h2> Accuracy score and Confusion Matrix</h2>

<img width="684" alt="2023-04-16 (2)" src="https://user-images.githubusercontent.com/102037657/232261834-9fffac08-b441-4b73-b30d-9f9ee2fc4279.png">

<h2> Epoch_Categorical_Accuracy</h2>
<img width="315" alt="2023-04-14 (8)" src="https://user-images.githubusercontent.com/102037657/232261835-0a009682-63b1-41c7-bdbc-e46d6e8f6229.png">
<h2> Epoch Loss</h2>
<img width="394" alt="2023-04-14 (7)" src="https://user-images.githubusercontent.com/102037657/232261837-5f05af1b-3ed2-440b-88b5-1a0e8f6752fc.png">
